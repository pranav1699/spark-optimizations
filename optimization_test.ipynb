{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe4aec7-1176-4ffc-a4bc-071f3bc2c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b0a410-49b6-48c5-9989-a4a8abe94b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 23:35:40 WARN Utils: Your hostname, pranav-Lenovo-ideapad-310-15IKB resolves to a loopback address: 127.0.1.1; using 192.168.1.10 instead (on interface wlp2s0)\n",
      "24/04/20 23:35:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/20 23:35:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Optimisation demo\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45ec633-7ea8-4d99-84e0-d4f82d1918e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.10:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Optimisation demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0633851090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facd3b3e-b27a-40de-966e-3cf49d047cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_time(func):\n",
    "    def inner_get_time() -> str:\n",
    "        start_time = time.time()\n",
    "        func()\n",
    "        end_time = time.time()\n",
    "        print(\"-\"*80)\n",
    "        return (f\"Execution time: {(end_time - start_time)*1000} ms\")\n",
    "    print(inner_get_time())\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ebbc30-8807-4cea-8709-bff9db533175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelism :  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Parallelism : \",spark.sparkContext.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c52f07-34c1-46f2-a8a7-19cf7b40d496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===================================================>     (28 + 3) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales data partitions :  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sales = spark.read.csv(\"data/flipkart/sales/*.csv\",header = True, inferSchema = True)\n",
    "print(\"sales data partitions : \",sales.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42713f-16c0-4ebb-97ce-48cd409669ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e250d5a9-deb4-4946-bd28-da29c11d2bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partition -> 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 22:08:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr1.csv\n",
      "24/04/20 22:08:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr2.csv\n",
      "24/04/20 22:08:36 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jul1.csv\n",
      "24/04/20 22:08:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun1.csv\n",
      "24/04/20 22:08:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun2.csv\n",
      "24/04/20 22:09:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may1.csv\n",
      "24/04/20 22:09:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may2.csv\n",
      "[Stage 8:=======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Execution time: 178456.2931060791 ms\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "@get_time\n",
    "def x():\n",
    "    sales = spark.read.csv(\"data/flipkart/sales/*.csv\",header = True, inferSchema = True)\n",
    "    print(f\"Number of Partition -> {sales.rdd.getNumPartitions()}\")\n",
    "    sales.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a52ca30d-f944-44a4-a2f0-3a1565d25e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 22:26:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr2.csv\n",
      "24/04/20 22:26:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jul1.csv\n",
      "24/04/20 22:26:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun1.csv\n",
      "24/04/20 22:26:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partition -> 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 22:27:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may1.csv\n",
      "24/04/20 22:27:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may2.csv\n",
      "24/04/20 22:27:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun2.csv\n",
      "[Stage 22:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Execution time: 147867.47097969055 ms\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"524288000\")\n",
    "\n",
    "\n",
    "@get_time\n",
    "def x():\n",
    "    sales = spark.read.csv(\"data/flipkart/sales/*.csv\",header = True, inferSchema = True)\n",
    "    # sales = sales.coalesce(8)\n",
    "    print(f\"Number of Partition -> {sales.rdd.getNumPartitions()}\")\n",
    "    sales.write.format(\"noop\").mode(\"overwrite\").save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b51c38-f355-47db-a641-c1f554a127a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling the AQE to manually test and optimize the performance\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b677f1a-6c79-4594-8efd-0ff7eae65163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partition -> 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 22:48:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr1.csv\n",
      "24/04/20 22:48:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr2.csv\n",
      "24/04/20 22:48:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jul1.csv\n",
      "24/04/20 22:49:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun1.csv\n",
      "24/04/20 22:49:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun2.csv\n",
      "24/04/20 22:49:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may1.csv\n",
      "24/04/20 22:49:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may2.csv\n",
      "24/04/20 22:49:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , product_id, product_name, unit, product_type, brand_name, manufacturer_name, l0_category, l1_category, l2_category, l0_category_id, l1_category_id, l2_category_id\n",
      " Schema: _c0, product_id, product_name, unit, product_type, brand_name, manufacturer_name, l0_category, l1_category, l2_category, l0_category_id, l1_category_id, l2_category_id\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/products/dim_product.csv\n",
      "[Stage 45:=====================================================>(395 + 4) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Execution time: 206940.043926239 ms\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"52428800\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",\"400\")\n",
    "\n",
    "@get_time\n",
    "def x():\n",
    "    sales = spark.read.csv(\"data/flipkart/sales/*.csv\",header = True, inferSchema = True)\n",
    "    products = spark.read.csv(\"data/flipkart/products/*.csv\", header= True, inferSchema = True)\n",
    "    # sales = sales.coalesce(8)\n",
    "    print(f\"Number of Partition -> {sales.rdd.getNumPartitions()}\")\n",
    "    city_products = (\n",
    "    sales.\n",
    "    join(products, on = [\"product_id\"] ,how = \"inner\")\n",
    "    # .select(\"city_name\",\"product_name\", \"procured_quantity\")\n",
    "    )\n",
    "\n",
    "    city_products.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c51aa177-babd-4d84-bfa7-7b234ac3ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"52428800\")\n",
    "# spark.conf.set(\"spark.sql.shuffle.partitions\",\"400\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "\n",
    "import random\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"800\")\n",
    "\n",
    "# UDF to return a random number every time and add to Employee as salt\n",
    "@udf\n",
    "def salt_udf():\n",
    "    return random.randint(0, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a07c4ee-d43a-488c-9993-2e1509a002f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sales = spark.read.csv(\"data/flipkart/sales/*.csv\",header = True, inferSchema = True)\n",
    "sales = slaes.drop(\"_c0\")\n",
    "products = spark.read.csv(\"data/flipkart/products/*.csv\",header = True, inferSchema = True)\n",
    "producs = products.drop(\"_c0\")\n",
    "# sales.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90bf6b18-79a1-4839-9f8a-96512003eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat\n",
    "\n",
    "# sales = spark.read.csv(\"data/flipkart/sales/*.csv\",header = True, inferSchema = True)\n",
    "# products = spark.read.csv(\"data/flipkart/products/*.csv\",header = True, inferSchema = True)\n",
    "\n",
    "salted_sales = sales.withColumn(\"salted_product_id\", concat(\"product_id\", lit(\"_\"), salt_udf()))\n",
    "\n",
    "salted_products= products.withColumn(\"salted_product_id\", concat(\"product_id\", lit(\"_\"), salt_udf()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c482cc-90ab-40f5-9cd7-8d611d1618bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 23:44:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr1.csv\n",
      "24/04/20 23:45:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_apr2.csv\n",
      "24/04/20 23:45:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jul1.csv\n",
      "24/04/20 23:45:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun1.csv\n",
      "24/04/20 23:45:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_jun2.csv\n",
      "24/04/20 23:46:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may1.csv\n",
      "24/04/20 23:46:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      " Schema: _c0, Unnamed: 0, date_, city_name, order_id, cart_id, dim_customer_key, procured_quantity, unit_selling_price, total_discount_amount, product_id, total_weighted_landing_price\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/sales/fact_sales_may2.csv\n",
      "24/04/20 23:46:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , product_id, product_name, unit, product_type, brand_name, manufacturer_name, l0_category, l1_category, l2_category, l0_category_id, l1_category_id, l2_category_id\n",
      " Schema: _c0, product_id, product_name, unit, product_type, brand_name, manufacturer_name, l0_category, l1_category, l2_category, l0_category_id, l1_category_id, l2_category_id\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pranav/Desktop/projects/learning/data/flipkart/products/dim_product.csv\n",
      "[Stage 11:===============================================>      (706 + 4) / 800]\r"
     ]
    }
   ],
   "source": [
    "# spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"52428800\")\n",
    "# spark.conf.set(\"spark.sql.shuffle.partitions\",\"400\")\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "@get_time\n",
    "def x():\n",
    "    # sales = spark.read.csv(\"data/flipkart/sales/*.csv\",header = True, inferSchema = True)\n",
    "    # products = spark.read.csv(\"data/flipkart/products/*.csv\", header= True, inferSchema = True)\n",
    "    # sales = sales.coalesce(8)\n",
    "    # print(f\"Number of Partition -> {sales.rdd.getNumPartitions()}\")\n",
    "    city_products = (\n",
    "    sales.\n",
    "    join(products, on = [\"product_id\"] ,how = \"inner\")\n",
    "    # .select(\"city_name\",\"product_name\", \"procured_quantity\")\n",
    "    )\n",
    "\n",
    "    city_products.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b74bc-282d-4e92-aeaf-c3313290aa25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
